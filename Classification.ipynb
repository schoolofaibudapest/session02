{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MNIST dataset***<br>\n",
    "Contains 70000 handwritten digits(60000 train, 10000 test), and labels for all the images.<br>\n",
    "For more info:<br>\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Keras CNN MNIST*** example code can be found here:<br>\n",
    "https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind, on a CPU the train could be take hours.<br>\n",
    "On my laptop 2 epochs took ~1,5 hour. Compare with a GPU performance, it's a huge difference.<br>\n",
    "GPU:<br>\n",
    "```\n",
    "60000/60000 [==============================] - 3s 49us/step - loss: 0.0286 - acc: 0.9914 - val_loss: 0.0294 - val_acc: 0.9910\n",
    "Epoch 12/12\n",
    "60000/60000 [==============================] - 3s 48us/step - loss: 0.0262 - acc: 0.9920 - val_loss: 0.0269 - val_acc: 0.9920\n",
    "Test loss: 0.026884999596639453\n",
    "Test accuracy: 0.992\n",
    "```\n",
    "Another option is train in the cloud.<br>\n",
    "***Google Colaboratory*** is a nice starting point for that. They give free GPU time to train your model.<br>\n",
    "For more info:<br>\n",
    "https://colab.research.google.com/notebooks/welcome.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks are similar to simple artificial NNs. The only difference is, the network assumption is to use images as inputs. That allow us to encode properties to the network architecture.<br>\n",
    "CNN = Artificial Neural Network + a set of operations we call Convolution.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Aritificial neurons*** simulate biological neurons in a limited way.<br>\n",
    "![title](notebook_contents/artificial_neuron.jpeg)\n",
    "The inputs represented as x1,x2, so on... which are connected to the activation function(f).<br>\n",
    "The connection between the inputs(x), and the activation function(f) dawned by a set of weights, which are represented W1, W2, so on...<br>\n",
    "Besides this, we have a bias(b). -TODO replace image<br>\n",
    "After applying the output of the activation function we got the 'output' as well, which is a function applied to the input, weighted by W and the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Convolution***<br>\n",
    "![title](notebook_contents/convolution.jpg)\n",
    "For now we stay at images.<br>\n",
    "We have a single input image, and we apply a filter(also known as kerner,mask) on it.<br>\n",
    "The image can represent as pixels*pixels, and if we use greyscaled pictures, the number between [0,255].<br>\n",
    "We get the result of the convolutional by combining the input window, weighted by the values inside the filter.<br>\n",
    "In this case the kernel was:\n",
    "```\n",
    "W0(1,0,1)\n",
    "W1(0,1,0)\n",
    "W2(1,0,1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN applied for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Firs layer is one or more layers of convolution.\n",
    "    After this we apply one or more steps of pooling.\n",
    "    We design a fully connected layer.\n",
    "    At the end we use some classification, like softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this method to create our CNN to classify digits on images from 0-9.<br>\n",
    "Let's get stated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's ***import the libraries*** we will use.<br>\n",
    "Keras will download the dataset for us.<br>\n",
    "backend - At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend. We use TensorFlow by default. You can check/change it in your /home/.keras/keras.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***batch_size =*** Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.<br>\n",
    "For more info:<br>\n",
    "https://keras.io/models/sequential/<br>\n",
    "***num_class =*** Just the classes we want to distinguish. In this case numbers from '0' to '9'.<br>\n",
    "***epochs =*** Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided.<br>\n",
    "For more info:<br>\n",
    "https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random.seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load the dataset images, and split them to train, and test datas.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Check the dataset:***<br>\n",
    "Lets take a look some of the train images. Every image(x_train) has a label(y_train).<br>\n",
    "Train image shape shows the actual image's shape. In this case we have 60000 images with 28x28 pixels.<br>\n",
    "Train labels shape just a 1D array that represent the actual/correct output for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape:(60000, 28, 28)\n",
      "train labels shape:[5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(\"{}\".format(y_train[i]))\n",
    "print(\"train images shape:{}\\ntrain labels shape:{}\".format(x_train.shape, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resize the images rows', and columbs' for faster processing.<br>***\n",
    "The 28x28 is a good starting point for hand written characters. As you can see above, the rows, and cols are already 28x28 pixels.<br>\n",
    "Also the model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Normalize the the datas.<br>***\n",
    "This is proprocessing step where we convert our data to float32 type, and normalize between range [0,1].<br>\n",
    "Almost all of the ML algorithms have better results if we normalize the datas, and also the converge can be much faster -> that improves the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The keras.utils.to_categorical function:***\n",
    "Use keras.utils.to_categorical on the train/test labels to converts a class vector (integers) to binary class matrix, because we will use categorical_crossentropy as well.<br>\n",
    "E.g.:\n",
    "```\n",
    "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "etc.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start the training, some useful information:\n",
    "\n",
    "### We use Sequential model:\n",
    "A linear stack of layers.<br>\n",
    "For more info:<br>\n",
    "https://keras.io/models/sequential/<br>\n",
    "https://keras.io/getting-started/sequential-model-guide/\n",
    "### Dense layer(aka. fully connected layer): \n",
    "Just your regular densely-connected NN layer. Where all the input is connected to all the outputs by a weight. Generally followed by an activation function. The layer has a weight matrix(w), a bias(b), and an activation(a).\n",
    "Other layers: Convolutional, Pooling, Normalisation, etc.<br>\n",
    "keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)<br>\n",
    "For more info:<br>\n",
    "https://keras.io/layers/core/<br>\n",
    "Also check out how can you create your own layer in Keras:<br>\n",
    "https://keras.io/layers/writing-your-own-keras-layers/\n",
    "### Conv2D is a 2D convolution layer (e.g. spatial convolution over images).\n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape.<br>\n",
    "keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)<br>\n",
    "For more info:<br>\n",
    "https://keras.io/layers/convolutional/\n",
    "### Dropout \n",
    "is a techniq to tackle overfitting. While the network is learning the weights of the neurons are tuned for specific features. Connected neurons have effect on this. If it's going too far, the model will be specialize for the training data. With dropout the model will be more adaptive. If we drop out randomly some neurons the other neurons have to step in and learn the predictions for the missing neurons. The network becomes less sensitive to the specific weights of neurons.<br>\n",
    "keras.layers.Dropout(rate, noise_shape=None, seed=None)<br>\n",
    "For more info:<br>\n",
    "https://keras.io/layers/core/#dropout\n",
    "### MaxPooling2D \n",
    "is a sample-based discretization process. We can down-sample the input representation, but keep the most important informations.<br>\n",
    "keras.layers.MaxPooling1D(pool_size=2, strides=None, padding='valid', data_format='channels_last')<br>\n",
    "For more info:<br>\n",
    "https://keras.io/layers/pooling/<br>\n",
    "https://www.quora.com/What-is-max-pooling-in-convolutional-neural-network<br>\n",
    "\n",
    "#### Also\n",
    "Check the loss functions:<br>\n",
    "https://keras.io/losses/<br>\n",
    "Check optimizers:<br>\n",
    "https://keras.io/optimizers/<br>\n",
    "Check the available activation functions:<br>\n",
    "https://keras.io/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[tensorboard])\n",
    "\n",
    "model.save('MNIST.h5')\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is only for testing purpose right now.<br>\n",
    "You have to save the picture before you do predict on it.<br>\n",
    "Still working on a robust solution for this.<br>\n",
    "I'll update with the final version, if it's available.<br>\n",
    "To use you have to change from 'Markdown' to 'Code'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image, ImageDraw\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import load_model\n",
    "import os\n",
    "#import base64\n",
    "%matplotlib inline\n",
    "\n",
    "canvas_width = 280\n",
    "canvas_height = 280\n",
    "line_width = int(canvas_width/10)\n",
    "image_width= 28\n",
    "image_height = 28\n",
    "white = (255, 255, 255)\n",
    "green = (0,128,0)\n",
    "image_number = 0\n",
    "\n",
    "def save(): #TODO now we have to save the image first to do predict.\n",
    "    global image_number\n",
    "    filename = f'image_{image_number}.jpg'\n",
    "    image.save(filename)\n",
    "    image_number += 1\n",
    "    \n",
    "def paint(event):\n",
    "    # python_green = \"#476042\"\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    cv.create_oval(x1, y1, x2, y2, fill=\"black\",width=line_width)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"black\",width=line_width)\n",
    "        \n",
    "def prediction():\n",
    "    global image_number\n",
    "    model = load_model('MNIST.h5')\n",
    "    img = load_img(f'image_{image_number-1}.jpg')\n",
    "    img = np.asarray(img)\n",
    "    img = cv2.resize(img,(image_width, image_height)) \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #plt.imshow(x)\n",
    "    preds = model.predict_classes(x)\n",
    "    prob = model.predict_proba(x)\n",
    "    try:\n",
    "        cv.delete(T)\n",
    "    except:\n",
    "        pass\n",
    "    T = Text(root, height=1, width=14)\n",
    "    T.pack()\n",
    "    T.insert(END, \"Prediction:{}\".format(preds[0]))\n",
    "    \n",
    "    print(preds, prob)\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"Predict\")\n",
    "root.configure(background='white')\n",
    "# Tkinter create a canvas to draw on\n",
    "cv = Canvas(root, width=canvas_width, height=canvas_height, bg='white')\n",
    "\n",
    "# PIL create an empty image and draw object to draw on\n",
    "# memory only, not visible\n",
    "image = PIL.Image.new(\"RGB\", (canvas_width, canvas_height), 'white')\n",
    "draw = ImageDraw.Draw(image)\n",
    "cv.bind(\"<B1-Motion>\", paint)\n",
    "cv.pack(expand=YES, fill=BOTH)\n",
    "\n",
    "button1=Button(text=\"predict\",command=prediction)\n",
    "button1.pack(side=LEFT)\n",
    "# TODO clear the Canvas.\n",
    "#button2=Button(root,fg=\"green\",text=\"Clear\",command=clear(cv, i))\n",
    "#button2.pack(side=RIGHT)\n",
    "button3=Button(root,fg=\"green\",text=\"Save\",command=save)\n",
    "button3.pack(side=RIGHT)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Used sources:***<br>\n",
    "https://keras.io<br>\n",
    "https://colab.research.google.com<br>\n",
    "https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks<br>\n",
    "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/<br>\n",
    "https://medium.com/technologymadeeasy/for-dummies-the-introduction-to-neural-networks-we-all-need-c50f6012d5eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
